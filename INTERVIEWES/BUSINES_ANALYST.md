# Business Analyst

## Responsibilities

### Gather source and target data requirements, identify and analyze datasets for data product suitability
Gathering source and target data requirements and analyzing datasets for data product suitability involves a systematic process that ensures the data meets the necessary criteria for the intended data product. Here are the steps to achieve this:

### 1. Define Objectives and Scope
- **Understand the Business Need**: Clarify the purpose of the data product and the business problem it aims to solve.
- **Identify Stakeholders**: Determine who will use the data product and involve them in the requirements gathering process.
- **Set Scope and Goals**: Outline the project scope, goals, and any constraints.

### 2. Gather Data Requirements
- **Identify Source Data**: List potential data sources (databases, APIs, flat files, etc.).
- **Determine Data Elements**: Identify specific data elements required, such as fields, attributes, or metrics.
- **Define Quality Requirements**: Establish criteria for data quality, including accuracy, completeness, consistency, and timeliness.
- **Document Metadata**: Capture metadata for each data element, including definitions, data types, formats, and sources.

### 3. Collect and Analyze Source Data
- **Data Collection**: Extract data samples from identified sources.
- **Profiling**: Use data profiling tools to understand the structure, content, and quality of the data.
- **Assess Suitability**: Evaluate if the source data meets the quality and structure required for the data product.
- **Data Cleaning**: Identify and rectify any issues such as missing values, duplicates, or inconsistencies.

### 4. Define Target Data Requirements
- **Data Model Design**: Design the target data model, including tables, relationships, and constraints.
- **Transformation Rules**: Define rules for transforming source data to the target model, including mappings and business logic.
- **Storage and Access**: Determine storage requirements and how the data will be accessed and queried.

### 5. Validate and Test Data
- **Sample Testing**: Load sample data into the target model to test transformation rules and validate against requirements.
- **Quality Assurance**: Conduct quality checks to ensure data integrity and compliance with defined requirements.
- **User Acceptance Testing (UAT)**: Have end-users test the data product to ensure it meets their needs and expectations.

### 6. Document and Communicate Findings
- **Requirement Specifications**: Document all source and target data requirements in a detailed specification.
- **Data Lineage**: Create documentation that tracks the flow of data from source to target, including all transformations.
- **Stakeholder Communication**: Regularly update stakeholders on progress, findings, and any issues encountered.

### Tools and Techniques
- **Data Profiling Tools**: Tools like Talend, Informatica, or Microsoft Power BI for profiling data.
- **ETL Tools**: Use Extract, Transform, Load (ETL) tools like Apache NiFi, Talend, or Informatica for data integration.
- **Data Modeling Tools**: Tools like ER/Studio, ERwin, or Microsoft Visio for designing data models.
- **SQL and Scripting**: Use SQL and scripting languages like Python for data extraction, transformation, and analysis.

### Best Practices
- **Iterative Approach**: Follow an iterative process, refining requirements and analysis based on feedback.
- **Collaboration**: Work closely with data owners, subject matter experts, and end-users throughout the process.
- **Documentation**: Maintain thorough documentation of requirements, processes, and decisions to ensure clarity and continuity.

By following these steps, you can ensure that the source and target data requirements are accurately gathered and analyzed, leading to a successful and suitable data product.
### Conduct detailed exploratory data analysis (EDA), generating insights on data gaps, trends, and areas for improvement

### Develop points of view (POVs) through data analysis to support product feature decisions

### Create and maintain source-to-target mapping documents and product-related documentation

### Develop and execute test scripts for Functional Testing and User Acceptance Testing (UAT) for data products

### Document data validation controls and collaborate with the engineering team to guide implementation

### Prepare data product release notes for operational readiness

### Participate in Program Increment (PI) planning, daily stand-up, sprint demo, and sprint retrospective meetings, fostering transparency, feedback, and continuous improvement.
 
## Skills & Qualifications:

### 6-8 years of experience in the Financial Services industry, with mandatory asset management experience. Investment operations and data management experience preferred

### Must have experience in detailed data analysis
